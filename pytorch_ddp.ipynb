{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ddp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ddp.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import pandas as pd\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# On Windows platform, the torch.distributed package only\n",
    "# supports Gloo backend, FileStore and TcpStore.\n",
    "# For FileStore, set init_method parameter in init_process_group\n",
    "# to a local file. Example as follow:\n",
    "# init_method=\"file:///f:/libtmp/some_file\"\n",
    "# dist.init_process_group(\n",
    "#    \"gloo\",\n",
    "#    rank=rank,\n",
    "#    init_method=init_method,\n",
    "#    world_size=world_size)\n",
    "# For TcpStore, same way as on Linux.\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '5554'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "    \n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(5, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "\n",
    "def demo_basic(rank, world_size):\n",
    "    print(f\"Running basic DDP example on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # create model and move it to GPU with id rank\n",
    "    model = ToyModel().to(rank)\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ddp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(rank)\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "def run_demo(demo_fn, world_size):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size,),\n",
    "             nprocs=world_size,\n",
    "             join=True)\n",
    "\n",
    "\n",
    "\n",
    "class ToyMpModel(nn.Module):\n",
    "    def __init__(self, dev0, dev1):\n",
    "        super(ToyMpModel, self).__init__()\n",
    "        self.dev0 = dev0\n",
    "        self.dev1 = dev1\n",
    "        self.net1 = torch.nn.Linear(5, 10).to(dev0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.net2 = torch.nn.Linear(10, 3).to(dev1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.dev0)\n",
    "        x = self.relu(self.net1(x))\n",
    "        x = x.to(self.dev1)\n",
    "        return self.net2(x)\n",
    "\n",
    "def demo_model_parallel(rank, world_size):\n",
    "    print(f\"Running DDP with model parallel example on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # setup mp_model and devices for this process\n",
    "    dev0 = (rank * 2) % world_size\n",
    "    dev1 = (rank * 2 + 1) % world_size\n",
    "    mp_model = ToyMpModel(dev0, dev1)\n",
    "    ddp_mp_model = DDP(mp_model)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # outputs will be on dev1\n",
    "    outputs = ddp_mp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(dev1)\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "def train_on_csv(rank, world_size, csv_file):\n",
    "    print(f\"Running DDP training on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # Load dataset from CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Assuming the last column is the target and all others are features\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    \n",
    "    num_classes = len(np.unique(y))  # Or your label encoder\n",
    "    \n",
    "    X = X.astype(np.float32)  # Convert features to float32\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = y.astype(np.int64)    # Convert labels to int64\n",
    "    \n",
    "    num_classes = len(np.unique(y))  # Or your label encoder\n",
    "    print(\"Number of classes:\", num_classes)\n",
    "\n",
    "    # Split data into train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #print(X_train)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Create a dataset and DataLoader\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, sampler=train_sampler)\n",
    "\n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = ToyModel().to(rank)\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(20):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        for batch in train_loader:\n",
    "            X_batch, y_batch = batch\n",
    "            X_batch, y_batch = X_batch.to(rank), y_batch.to(rank)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = ddp_model(X_batch)\n",
    "            #print(\"Output- \",outputs)\n",
    "            #print(\"y- \",y_batch)\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Rank {rank}, Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    \n",
    "    if rank == 0:\n",
    "        model_save_path = \"ddp_model.pth\"\n",
    "        torch.save(ddp_model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved at {model_save_path}\")\n",
    "    \n",
    "\n",
    "    cleanup()\n",
    "    \n",
    "def run_demo(demo_fn, world_size, csv_file):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size, csv_file),\n",
    "             nprocs=world_size,\n",
    "             join=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    print(f\"total GPUs: {n_gpus}\")\n",
    "    assert n_gpus >= 2, f\"Requires at least 2 GPUs to run, but got {n_gpus}\"\n",
    "    world_size = n_gpus\n",
    "    csv_file = \"Iris.csv\"  # Update this path to your CSV file\n",
    "\n",
    "    run_demo(train_on_csv, world_size, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total GPUs: 2\n",
      "Running DDP training on rank 1.\n",
      "Running DDP training on rank 0.\n",
      "Number of classes: 3\n",
      "Number of classes: 3\n",
      "Rank 1, Epoch 1, Loss: 0.9878944754600525\n",
      "Rank 0, Epoch 1, Loss: 0.9715988039970398\n",
      "Rank 0, Epoch 2, Loss: 1.0844911336898804\n",
      "Rank 1, Epoch 2, Loss: 1.1329790353775024\n",
      "Rank 1, Epoch 3, Loss: 1.2353006601333618\n",
      "Rank 0, Epoch 3, Loss: 1.0441750288009644\n",
      "Rank 0, Epoch 4, Loss: 1.185050368309021\n",
      "Rank 1, Epoch 4, Loss: 1.100276231765747\n",
      "Rank 1, Epoch 5, Loss: 1.0763195753097534\n",
      "Rank 0, Epoch 5, Loss: 1.0393908023834229\n",
      "Rank 0, Epoch 6, Loss: 1.0644296407699585\n",
      "Rank 1, Epoch 6, Loss: 0.9357036352157593\n",
      "Rank 0, Epoch 7, Loss: 1.2093515396118164\n",
      "Rank 1, Epoch 7, Loss: 0.9351874589920044\n",
      "Rank 1, Epoch 8, Loss: 1.035475254058838\n",
      "Rank 0, Epoch 8, Loss: 0.9917013049125671\n",
      "Rank 0, Epoch 9, Loss: 0.8907645344734192\n",
      "Rank 1, Epoch 9, Loss: 1.1606793403625488\n",
      "Rank 1, Epoch 10, Loss: 1.1588400602340698\n",
      "Rank 0, Epoch 10, Loss: 1.0529487133026123\n",
      "Rank 1, Epoch 11, Loss: 1.0974407196044922\n",
      "Rank 0, Epoch 11, Loss: 1.0900508165359497\n",
      "Rank 0, Epoch 12, Loss: 0.8951305150985718\n",
      "Rank 1, Epoch 12, Loss: 1.2228399515151978\n",
      "Rank 1, Epoch 13, Loss: 1.033341884613037\n",
      "Rank 0, Epoch 13, Loss: 1.0759165287017822\n",
      "Rank 1, Epoch 14, Loss: 0.9908591508865356\n",
      "Rank 0, Epoch 14, Loss: 1.1211447715759277\n",
      "Rank 0, Epoch 15, Loss: 1.0503345727920532\n",
      "Rank 1, Epoch 15, Loss: 1.0356910228729248\n",
      "Rank 0, Epoch 16, Loss: 1.075995922088623\n",
      "Rank 1, Epoch 16, Loss: 1.032872200012207\n",
      "Rank 1, Epoch 17, Loss: 0.9165365099906921\n",
      "Rank 0, Epoch 17, Loss: 1.0420572757720947\n",
      "Rank 1, Epoch 18, Loss: 1.2198817729949951\n",
      "Rank 0, Epoch 18, Loss: 1.0078926086425781\n",
      "Rank 1, Epoch 19, Loss: 1.0164391994476318\n",
      "Rank 0, Epoch 19, Loss: 1.163567304611206\n",
      "Rank 0, Epoch 20, Loss: 1.0199716091156006\n",
      "Rank 1, Epoch 20, Loss: 0.9506163597106934\n",
      "Model saved at ddp_model.pth\n"
     ]
    }
   ],
   "source": [
    "!python ddp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1471, -0.2529,  0.5504]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(5, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model and load the saved state dict\n",
    "model = ToyModel().to(device)\n",
    "\n",
    "# Load the saved state_dict\n",
    "state_dict = torch.load(\"ddp_model.pth\", map_location=device)\n",
    "\n",
    "# Remove 'module.' prefix from the keys in the state_dict if present\n",
    "state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}\n",
    "\n",
    "# Load the corrected state_dict into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Example usage (e.g., for inference)\n",
    "input_data = torch.randn(1, 5).to(device)  # Example input for the model\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
